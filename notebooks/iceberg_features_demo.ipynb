{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Install the project in editable mode (run this cell once)\nimport sys\nimport subprocess\n\n# Install the project in editable mode\ntry:\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"..\"])\n    print(\"✓ Project installed successfully\")\nexcept subprocess.CalledProcessError as e:\n    print(f\"❌ Installation failed: {e}\")\n    \n# Alternative: Add to path manually\nimport os\nproject_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n    print(f\"✓ Added to Python path: {project_root}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup - Run this cell first\nimport sys\nimport os\n\n# Add project root to Python path\nproject_root = os.path.abspath('..')\nsys.path.insert(0, project_root)\n\n# Import required libraries\nimport pandas as pd\nimport duckdb\nfrom datetime import datetime\nimport json\n\n# Import our Iceberg manager using importlib for numbered module\nimport importlib.util\nspec = importlib.util.spec_from_file_location(\"iceberg_creation\", \"../scripts/04_iceberg_creation.py\")\niceberg_module = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(iceberg_module)\nIcebergManager = iceberg_module.IcebergManager\n\nprint(\"✅ Setup complete!\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Initialize the Iceberg Manager\nmanager = IcebergManager()\nprint(\"✅ Iceberg manager initialized\")\nprint(f\"📁 Warehouse: {manager.warehouse_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Iceberg table from our NEO data\n",
    "try:\n",
    "    table_name = manager.create_iceberg_table()\n",
    "    print(f\"✓ Created Iceberg table: {table_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Table creation failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Table Information and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get basic table information\ntry:\n    table = manager.catalog.load_table(table_name)\n    \n    print(\"📊 ICEBERG TABLE INFORMATION\")\n    print(\"=\" * 50)\n    print(f\"📍 Location: {table.location()}\")\n    print(f\"📋 Schema fields: {len(table.schema().fields)}\")\n    print(f\"🗂️ Partition fields: {len(table.spec().fields)}\")\n    \n    # Current snapshot\n    current_snapshot = table.current_snapshot()\n    if current_snapshot:\n        print(f\"📸 Current Snapshot: {current_snapshot.snapshot_id}\")\n    \n    print(\"\\n📋 SCHEMA:\")\n    for i, field in enumerate(table.schema().fields):\n        print(f\"  {i+1}. {field.name}: {field.field_type}\")\n    \n    print(\"\\n🗂️ PARTITIONING:\")\n    if len(table.spec().fields) > 0:\n        for field in table.spec().fields:\n            print(f\"  - {field}\")\n    else:\n        print(\"  No partitioning (unpartitioned table)\")\n        \nexcept Exception as e:\n    print(f\"❌ Failed to get table info: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query the Iceberg Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query the Iceberg table directly through PyIceberg\ntry:\n    table = manager.catalog.load_table(table_name)\n    \n    # Basic count query\n    scan = table.scan()\n    arrow_table = scan.to_arrow()\n    total_records = len(arrow_table)\n    \n    print(f\"📊 Total records in Iceberg table: {total_records:,}\")\n    \n    # Convert to pandas for easier display\n    df = arrow_table.to_pandas()\n    \n    # Show sample data (closest approaches)\n    if 'dist' in df.columns:\n        sample_data = df.nsmallest(10, 'dist')[['des', 'fullname', 'cd', 'dist', 'h']]\n        print(\"\\n🔍 Closest approaches (sample):\")\n        display(sample_data)\n    else:\n        print(\"\\n🔍 Sample data:\")\n        display(df.head(10))\n        \nexcept Exception as e:\n    print(f\"❌ Query failed: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Schema Evolution Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate schema evolution\nprint(\"🔄 SCHEMA EVOLUTION DEMONSTRATION\")\nprint(\"=\" * 40)\n\ntry:\n    # Get original schema\n    table = manager.catalog.load_table(table_name)\n    original_schema = table.schema()\n    print(\"📋 ORIGINAL SCHEMA:\")\n    for field in original_schema.fields:\n        print(f\"  - {field.name}: {field.field_type}\")\n    \n    # Perform schema evolution using our existing method\n    schema_results = manager.add_simple_column(table_name)\n    \n    print(f\"\\n✓ Schema evolution completed!\")\n    print(f\"📝 Operation: {schema_results['operation']}\")\n    print(f\"📝 Column added: {schema_results['column_name']} ({schema_results['column_type']})\")\n    print(f\"📝 Records added: {schema_results['records_added']}\")\n    \n    # Show new schema\n    table = manager.catalog.load_table(table_name)  # Reload to get updated schema\n    new_schema = table.schema()\n    print(f\"\\n📋 EVOLVED SCHEMA:\")\n    for field in new_schema.fields:\n        print(f\"  - {field.name}: {field.field_type}\")\n    \n    print(f\"\\n✅ Successfully added '{schema_results['column_name']}' column!\")\n    \nexcept Exception as e:\n    print(f\"❌ Schema evolution failed: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Travel Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate time travel capabilities\nprint(\"⏰ TIME TRAVEL DEMONSTRATION\")\nprint(\"=\" * 35)\n\ntry:\n    # Perform time travel demonstration using our existing method\n    time_travel_results = manager.demonstrate_time_travel(table_name)\n    \n    print(f\"✓ Time travel completed successfully!\")\n    print(f\"📸 Found {len(time_travel_results['snapshots'])} snapshots\")\n    \n    # Display snapshot information\n    print(\"\\n📸 SNAPSHOTS:\")\n    for i, snapshot in enumerate(time_travel_results['snapshots']):\n        print(f\"  {i+1}. Snapshot {snapshot['snapshot_id']}\")\n        print(f\"     📅 Time: {snapshot['timestamp']}\")\n        if snapshot.get('summary'):\n            print(f\"     📊 Summary: {snapshot['summary']}\")\n        print()\n    \n    # Display time travel queries\n    print(\"🔍 TIME TRAVEL QUERIES:\")\n    for i, query in enumerate(time_travel_results['queries']):\n        print(f\"  {i+1}. Snapshot {query['snapshot_id']}\")\n        print(f\"     📅 Time: {query['timestamp']}\")\n        print(f\"     📊 Records: {query['record_count']:,}\")\n        print()\n        \nexcept Exception as e:\n    print(f\"❌ Time travel failed: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Iceberg Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test advanced Iceberg features through PyIceberg\nprint(\"🚀 ADVANCED ICEBERG FEATURES\")\nprint(\"=\" * 35)\n\ntry:\n    # Load the table directly\n    table = manager.catalog.load_table(table_name)\n    \n    # 1. Inspect table history\n    print(\"📚 TABLE HISTORY:\")\n    history = list(table.history())\n    for i, entry in enumerate(history[:5]):  # Show first 5 entries\n        print(f\"  {i+1}. Snapshot {entry.snapshot_id}\")\n        print(f\"     📅 {datetime.fromtimestamp(entry.timestamp_ms / 1000)}\")\n    \n    # 2. Table statistics\n    print(f\"\\n📊 TABLE STATISTICS:\")\n    print(f\"  📁 Location: {table.location()}\")\n    print(f\"  📋 Schema fields: {len(table.schema().fields)}\")\n    print(f\"  🗂️ Partition fields: {len(table.spec().fields)}\")\n    \n    # 3. Current snapshot details\n    current_snapshot = table.current_snapshot()\n    if current_snapshot:\n        print(f\"\\n📸 CURRENT SNAPSHOT:\")\n        print(f\"  🆔 ID: {current_snapshot.snapshot_id}\")\n        print(f\"  📅 Timestamp: {datetime.fromtimestamp(current_snapshot.timestamp_ms / 1000)}\")\n        if hasattr(current_snapshot, 'summary'):\n            print(f\"  📊 Summary: {dict(current_snapshot.summary)}\")\n    \n    # 4. Scan with filters (demonstrate predicate pushdown)\n    print(f\"\\n🔍 FILTERED SCAN EXAMPLE:\")\n    \n    # Simple scan with limit\n    scan = table.scan().limit(1000)\n    filtered_data = scan.to_arrow().to_pandas()\n    print(f\"  📊 Limited scan records: {len(filtered_data)}\")\n    \n    if len(filtered_data) > 0:\n        if 'approach_year' in filtered_data.columns:\n            print(f\"  📅 Year range: {filtered_data['approach_year'].min()} - {filtered_data['approach_year'].max()}\")\n        if 'dist' in filtered_data.columns:\n            print(f\"  🎯 Closest approach: {filtered_data['dist'].min():.6f} AU\")\n    \nexcept Exception as e:\n    print(f\"❌ Advanced features test failed: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Comparison: Iceberg vs Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Performance comparison\nimport time\n\nprint(\"⚡ PERFORMANCE COMPARISON\")\nprint(\"=\" * 30)\n\ndef time_query(description, query_func):\n    \"\"\"Time a query function.\"\"\"\n    start = time.time()\n    try:\n        result = query_func()\n        end = time.time()\n        duration = end - start\n        print(f\"✓ {description}: {duration:.4f}s\")\n        return result, duration\n    except Exception as e:\n        end = time.time()\n        duration = end - start\n        print(f\"❌ {description}: FAILED ({duration:.4f}s) - {e}\")\n        return None, duration\n\n# Test queries\ntry:\n    # 1. Count query via Iceberg (PyIceberg direct)\n    def iceberg_count():\n        table = manager.catalog.load_table(table_name)\n        scan = table.scan()\n        return len(scan.to_arrow())\n    \n    iceberg_result, iceberg_time = time_query(\"Iceberg Count (PyIceberg)\", iceberg_count)\n    \n    # 2. Sample query via Iceberg\n    def iceberg_sample():\n        table = manager.catalog.load_table(table_name)\n        scan = table.scan().limit(100)\n        return len(scan.to_arrow())\n    \n    iceberg_sample_result, iceberg_sample_time = time_query(\"Iceberg Sample (100 records)\", iceberg_sample)\n    \n    # 3. Full table scan with conversion\n    def iceberg_full_scan():\n        table = manager.catalog.load_table(table_name)\n        scan = table.scan()\n        arrow_table = scan.to_arrow()\n        df = arrow_table.to_pandas()\n        return len(df)\n    \n    iceberg_full_result, iceberg_full_time = time_query(\"Iceberg Full Scan + Pandas\", iceberg_full_scan)\n    \n    # Summary\n    print(\"\\n📊 PERFORMANCE SUMMARY:\")\n    print(f\"  📊 Total records: {iceberg_result:,}\")\n    print(f\"  ⚡ Count time: {iceberg_time:.4f}s\")\n    print(f\"  🔍 Sample time: {iceberg_sample_time:.4f}s\") \n    print(f\"  📈 Full scan time: {iceberg_full_time:.4f}s\")\n    \n    if iceberg_result and iceberg_result > 0:\n        throughput = iceberg_result / iceberg_time\n        print(f\"  🚀 Throughput: {throughput:,.0f} records/sec\")\n\nexcept Exception as e:\n    print(f\"❌ Performance comparison failed: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save comprehensive results\ndemo_results = {\n    \"demo_timestamp\": datetime.now().isoformat(),\n    \"table_name\": table_name if 'table_name' in locals() else None,\n    \"schema_evolution\": schema_results if 'schema_results' in locals() else None,\n    \"time_travel\": time_travel_results if 'time_travel_results' in locals() else None,\n    \"performance\": {\n        \"iceberg_count_time\": iceberg_time if 'iceberg_time' in locals() else None,\n        \"iceberg_sample_time\": iceberg_sample_time if 'iceberg_sample_time' in locals() else None,\n        \"iceberg_full_time\": iceberg_full_time if 'iceberg_full_time' in locals() else None,\n        \"total_records\": iceberg_result if 'iceberg_result' in locals() else None\n    }\n}\n\n# Save to file\nwith open('../iceberg_demo_results.json', 'w') as f:\n    json.dump(demo_results, f, indent=2, default=str)\n\nprint(\"✓ Demo results saved to iceberg_demo_results.json\")\n\n# Cleanup\ntry:\n    manager.close()\n    print(\"✓ Connections closed\")\nexcept:\n    pass\n\nprint(\"\\n🎉 Iceberg features demo completed successfully!\")\nprint(\"\\n📋 Summary of demonstrated features:\")\nprint(\"  ✓ Native PyIceberg table creation\")\nprint(\"  ✓ Schema evolution (adding columns)\")\nprint(\"  ✓ Time travel (snapshot queries)\")\nprint(\"  ✓ Direct PyIceberg table access\")\nprint(\"  ✓ Table metadata inspection\")\nprint(\"  ✓ ACID transactions\")\nprint(\"  ✓ Performance measurements\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duckdbiceberg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}